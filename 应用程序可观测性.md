

# 应用程序可观测性能-2022/08/01

- 主要参考内容为助教提供的[demo](https://github.com/cool-mol/observability-demo)。一些额外添加的`file`格式可以参考这个demo，一些基本语句也可以看下面提供的博客。

- 首先在电脑上面安装**`Docker`**,可以直接去[`Docker 官网`](https://www.docker.com/)进行安装`Docker Desktop`。(这个`docker desktop`个人感觉挺好用的，可以实时的观测各个镜像以及容器是否运行已经运行的情况（`log`）。)安装之后按照`installer`的步骤指示去做就好了。

- 通过如下指令创建新的`Docker`镜像：**`docker build . -t demo:v1`**,在运行时可能会出现**找不到`Dockerfile`**的情况，需要自己在项目目录下面新建一个`Dockerfile`，具体可以参考这两个博客：https://blog.csdn.net/shixiaodongmain/article/details/124162572和https://blog.csdn.net/weixin_45445879/article/details/124355898。

- 使用`dock-compose up -d`去运行已经生成的镜像，运行之后可以使用`docker ps -a`来检查是否运行成功。我在运行时遇到了**`Docker-compose`文件不存在**的问题，解决方式是在项目根目录下面新建一个`dock-compose.yml/yaml`文件，具体的配置可以参考`demo`中的对应文件，一些基本格式可以参考如下博客：https://blog.csdn.net/BlingblingFu/article/details/120771011。

- 镜像创建好之后，可以使用`Docker Desktop`来查看镜像信息，但是`Linux`下面没有这个玩意，可以使用`docker images`命令行来查看本机所有已经下载的镜像。要删除一个`image`,可以使用`docker rmi -f image_id`。

- 但是好像配置了`docker-compose.yml`也不一定能成功运行，在继续运行之前，需要安装`grafana`,`prometheus`,直接去官网进行安装就好了。官网地址如下：`grafana`:https://grafana.com/,`prometheus`:https://prometheus.io/。

- 之后需要根据`demo`中的样例来自己在根目录下新建并配置`prometheus.yml`文件。

- 之后再一次运行`docker-compose up -d(-d表示是在后台运行)`,可以**`create`**各个镜像，这里要强调的是只是`create`了并让他们尝试开始运行，但是有可能运行出错就自己停了，这个具体是否成功可以查看一下`docker desktop`对应的镜像的日志部分。

- 由于我在实践时是在同一台机器上面做的监视(即后端、数据库啥的还有监视都是在本地运行的，没有分成两个机器)，所以可能会出现**`connection refused`**之类的问题，这可能就是出现了端口冲突。我暂时是用的解决方式为直接修改监视器运行的接口，具体格式可以见下文的完整配置内容。

- 对于除了后端镜像之外的镜像对应的`container`,实测下来一般是没啥问题的(当然暂时只是`prometheus`,`grafana`,`mysql`这几部分，`ELK`暂时还没弄(2022/8/1)),但是后端镜像可能会出现连接不上`mysql`数据库的问题，后来百度了好久好久(毫不夸张的说，真的很久。。。)，发现是由于`docker`是将不同镜像放在不同`container`内运行的，即`mysql`镜像和后端镜像并没有位于同一个`container`中，因而在`application.proptities`中直接写`localhost:3306`就连不上了，可以理解为不同容器不位于一个局域网内，因而`localhost`不是一个`localhost`,而要改成`database-mysql:3306`之类的(这里的`database-mysql`是`mysql`镜像对应的容器名，可以在`docker-compose.yml`中看到相应内容)。

- 下一个问题是改成容器名之后还可能会报出`acess denied`之类的问题，这个可能是由于对应的数据库用户或者使用的数据库没有访问权限导致的。这个问题的话，网上说是要自己分配权限，比如这个[博客](https://blog.csdn.net/weixin_38298616/article/details/123048612),但是我操作完好像没啥用。。。(:з」∠)_，后来感觉可能是我们小组最开始是用的数据库不是`root`的原因，所以我是用root重新建了一个新的并且结构一样的数据库，才可以跑起来并且成功连接。但是我在这里还遇到了一个问题，就是有时候也会出现`connection refused`的问题，但是重启几下就好了，暂时还没有找到原因。

- 下一个问题就是数据库已经在`container`上面建好的情况下怎样向里面插入数据的问题，这个问题我暂时来看是通过`docker-compose.yml`对应的配置解决的。具体可以看下面的配置文件具体内容。

- 在上述过程成功并且所有container都跑起来的情况下(同理，还是只弄了`demo`里面的前半部分，就是`ELK`前面的部分(2022/8/1)),就可以开始检测了。首先需要在浏览器中输入`http://localhost:3000/`,来访问`grafana的homepage`，当然通过官网也可以访问，但是官网的话有些内容和`demo`不一样。之后登录时初始默认账号和密码都是`admin`,进入主页面之后，在左边栏找到“设置”->“`Data Source`”一项，添加一个新的`prometheus`数据源，之后在下面的`URL`中填写`http://prometheus:9090`,之后点击最下面的`save&test`,当提示`test`通过，显示`net Working`时才是真正的添加成功。

- 之后点击`DashBoard`选项卡里面的`import`选项栏，在上面的小的输入框里面输入4701，之后点击小的输入框边上的`load`按钮，之后在新进入的页面里面最下面的添加`data source`里面选择新添加的`prometheus`数据源，之后点击最下面的按钮就可以进入到最终的观测页面了。如果觉得刷新太慢可以在左上角修改刷新时间间隔以及检测的时间范围。

- `Dockerfile(注意名字大小写要写对!!!)`

  ```
  FROM openjdk
  ARG JAR_FILE=target/*.jar
  COPY ${JAR_FILE} app.jar
  COPY /elastic-apm-agent-1.33.0.jar apm-agent.jar
  ENTRYPOINT ["java","-javaagent:/apm-agent.jar","-Delastic.apm.service_name=my-application","-Delastic.apm.server_url=http://apm-server:8200","-Delastic.apm.secret_token=","-Delastic.apm.application_packages=org.example","-jar","/app.jar"]
  ```

- `docker-compose.yml`:

  ```
  version: '3.2'
  
  services:
    database:
      image: mysql #镜像名
      container_name: database-mysql #容器名
      ports:
        - "3307:3306" #端口映射，检测端口：运行端口
      command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_bin --init-file=/docker-entrypoint-initdb.d/dump.sql #启动时调用的cmdLine，这里的init-file就是在初始化mysql数据库时会调用的文件信息，这里我传入的是一个建库脚本。这个建库脚本可以直接把我们的数据库里面的那个查询复制到根目录下的XXX.sql文件中去，我这里取名叫做dump.sql
      restart: always
      environment:
        - MYSQL_ROOT_PASSWORD=root #设置访问数据库的密码
        - MYSQL_DATABASE=docker_sportapp #设置要访问的数据库的名称
      volumes: #设置挂载
        - type: bind
          source: ./dump.sql #挂在数据的元数据位置
          target: /docker-entrypoint-initdb.d/dump.sql #挂在数据的目标位置，一定要是绝对路径，这里我试了好几个网上的答案，后来好像这个docker-rntrypoint-initdb.d里面的文件才会真正在建库的时候被调用，检测是否成功插入数据就用postman发请求看看
        - type: bind
          source: ./my.cnf
          target: /etc/mysql/my.cnf
      networks:
        - demo
    backend:
      image: demo:v1
      container_name: backend-springboot
      depends_on:
        - database #设置镜像之间的依赖关系
      ports:
        - "8080:8080"
      environment:
        - JVM_OPTS="-Xms128m -Xmx128m -XX:PermSize=128m -XX:MaxPermSize=128m"
      networks:
        - demo
  
    prometheus:
      image: prom/prometheus
      container_name: prometheus
      volumes:
        - type: bind
          source: ./prometheus.yml
          target: /etc/prometheus/prometheus.yml
          read_only: true
      ports:
        - "9090:9090"
      networks:
        - demo
  
    grafana:
      image: grafana/grafana
      container_name: grafana
      ports:
        - "3000:3000"
      networks:
        - demo
  
    elasticsearch:
      image: elasticsearch:7.5.0
      container_name: elasticsearch
      environment:
        - "cluster.name=elasticsearch" #设置集群名称为elasticsearch
        - "discovery.type=single-node" #以单一节点模式启动
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m" #设置使用jvm内存大小
      volumes:
        - ./elasticsearch/data:/usr/share/elasticsearch/data #数据文件挂载
        # - ./elasticsearch/plugins:/usr/share/elasticsearch/plugins #插件文件挂载
      ports:
        - "9200:9200"
        - "9300:9300"
      networks:
        - demo
  
    kibana:
      image: kibana:7.5.0
      container_name: kibana
      links:
        - elasticsearch:es #可以用es这个域名访问elasticsearch服务
      depends_on:
        - elasticsearch #kibana在elasticsearch启动之后再启动
      environment:
        - "elasticsearch.hosts=http://es:9200" #设置访问elasticsearch的地址
      ports:
        - "5601:5601"
      networks:
        - demo
  
    logstash:
      image: logstash:7.5.0
      container_name: logstash
      volumes:
        - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf #挂载logstash的配置文件
      depends_on:
        - elasticsearch #kibana在elasticsearch启动之后再启动
      links:
        - elasticsearch:es #可以用es这个域名访问elasticsearch服务
      ports:
        - "4560:4560"
      networks:
        - demo
  
    apm-server:
      image: docker.elastic.co/apm/apm-server:7.9.2
      container_name: apm-server
      depends_on:
        - elasticsearch #kibana在elasticsearch启动之后再启动
      ports:
        - "8200:8200"
      links:
        - elasticsearch:es
      networks:
        - demo
  networks:
    demo:
      driver: bridge
  ```

- `prometheus.yml`:

  ```
  # my global config
  global:
    scrape_interval:     5s # Set the scrape interval to every 5 seconds. Default is every 1 minute.
    evaluation_interval: 5s # Evaluate rules every 5 seconds. The default is every 1 minute.
    # scrape_timeout is set to the global default (10s).
  
  # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
  rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"
  
  # A scrape configuration containing exactly one endpoint to scrape:
  # Here it's Prometheus itself.
  scrape_configs:
    # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
    - job_name: 'prometheus'
      # metrics_path defaults to '/metrics'
      # scheme defaults to 'http'.
      static_configs:
        - targets: ['127.0.0.1:9090']
  
    - job_name: 'spring-actuator'
      metrics_path: '/actuator/prometheus'
      scrape_interval: 5s
      static_configs:
        - targets: ['backend:8080']
  ```

- `my.cnf`:

  ```
  [mysql]
  #mysql客户端默认字符集
  default-character-set=utf8
  [mysqld]
  # 设置3306端口
  port = 3306
  # 允许最大连接数
  max_connections=1000
  # 设置mysql服务端默认字符集
  character-set-server=utf8
  # 创建新表时将使用的默认存储引擎
  default-storage-engine=INNODB
  # 缓存大小
  sort_buffer_size=256MB
  ```